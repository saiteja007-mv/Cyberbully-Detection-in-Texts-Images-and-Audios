{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43693,"status":"ok","timestamp":1677830762278,"user":{"displayName":"bobby mothukuri","userId":"00961739428794661697"},"user_tz":-330},"id":"3O5S0i_anicv","outputId":"1d09bed9-a81d-4664-8c49-b71068d87e1d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"3O5S0i_anicv"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4352,"status":"ok","timestamp":1677830766624,"user":{"displayName":"bobby mothukuri","userId":"00961739428794661697"},"user_tz":-330},"id":"QfVkJDB-oORr","outputId":"a7071d66-1c7c-46b1-f793-c6f6e241debe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub\n","Successfully installed pydub-0.25.1\n"]}],"source":["pip install pydub"],"id":"QfVkJDB-oORr"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6620,"status":"ok","timestamp":1677830773237,"user":{"displayName":"bobby mothukuri","userId":"00961739428794661697"},"user_tz":-330},"id":"iuabnRRKoQ9X","outputId":"a3e958f7-5119-4c00-9a93-168d1d69a1b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting SpeechRecognition\n","  Downloading SpeechRecognition-3.9.0-py2.py3-none-any.whl (32.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting requests>=2.26.0\n","  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.0.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.14)\n","Installing collected packages: requests, SpeechRecognition\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.25.1\n","    Uninstalling requests-2.25.1:\n","      Successfully uninstalled requests-2.25.1\n","Successfully installed SpeechRecognition-3.9.0 requests-2.28.2\n"]}],"source":["pip install SpeechRecognition"],"id":"iuabnRRKoQ9X"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8297,"status":"ok","timestamp":1677830781528,"user":{"displayName":"bobby mothukuri","userId":"00961739428794661697"},"user_tz":-330},"id":"94062f19-a311-4514-8354-a7189e0b1229","outputId":"5803f591-585d-458d-bb06-d8ddf01ab0f5"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","import functools, re\n","import random\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from textblob import TextBlob\n","from pydub import AudioSegment"],"id":"94062f19-a311-4514-8354-a7189e0b1229"},{"cell_type":"code","execution_count":null,"metadata":{"id":"6b6f3b84-c3e7-4e8f-b171-f1fc178bfe6d"},"outputs":[],"source":["# Load the model\n","text_model =  tf.keras.models.load_model('/content/drive/MyDrive/Project/models/cyberbullying_model_bilstm.h5')\n","image_model =  tf.keras.models.load_model('/content/drive/MyDrive/Project/models/cyberbullying_model_bilstm_image.h5')\n","#load the dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/Project/twitter.csv\")\n","stopwords = set(stopwords.words(\"english\"))\n","stopwords = [i.lower() for i in nltk.corpus.stopwords.words('english') + [chr(i) for i in range(97, 123)]]\n","x = df.tweet_text.apply(lambda text: re.sub(\"\\s+\", \" \", ' '.join([i for i in re.sub(\"[^9A-Za-z ]\", \"\" , re.sub(\"\\\\n\", \"\", re.sub(\"\\s+\", \" \", re.sub(r'http\\S+', '', text.lower())))).split(\" \") if i not in stopwords]))).values.astype(str)\n","y = pd.get_dummies(df.cyberbullying_type)\n","labels = list(y.columns)"],"id":"6b6f3b84-c3e7-4e8f-b171-f1fc178bfe6d"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":645},"executionInfo":{"elapsed":45222,"status":"ok","timestamp":1677831586189,"user":{"displayName":"bobby mothukuri","userId":"00961739428794661697"},"user_tz":-330},"id":"9cd651d2-71ba-4462-a906-b76237bd192f","outputId":"af390b30-8109-4d98-f009-c51e5c2637fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter choice:\n","1.Text\n","2.Image\n","3.Audio\n","4.Exit\n","1\n","Enter text to check whether it is bully or notYou are ugly\n","1/1 [==============================] - 0s 71ms/step\n","The text is cyberbullying\n","Enter choice:\n","1.Text\n","2.Image\n","3.Audio\n","4.Exit\n","2\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-8ca4241e-1663-492d-be0e-4da6a5bbbfe7\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-8ca4241e-1663-492d-be0e-4da6a5bbbfe7\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"name":"stdout","output_type":"stream","text":["Saving Non_bully (5).jpg to Non_bully (5) (1).jpg\n","1/1 [==============================] - 1s 510ms/step\n","Not Bullying\n","Enter choice:\n","1.Text\n","2.Image\n","3.Audio\n","4.Exit\n","3\n","Enter filenameaudio1\n","you are beautiful\n","1/1 [==============================] - 0s 46ms/step\n","The audio is not cyber bullying\n","Enter choice:\n","1.Text\n","2.Image\n","3.Audio\n","4.Exit\n","4\n"]}],"source":["from tkinter import Tk, filedialog, Button, Label\n","import speech_recognition as sr\n","from PIL import Image\n","import cv2\n","import os\n","#from IPython.display import Image\n","from google.colab import files\n","from PIL import Image\n","\n","def sentiment_analysis(text):\n","        analysis = TextBlob(text)\n","        if analysis.sentiment.polarity > 0:\n","            return 1\n","        elif analysis.sentiment.polarity == 0:\n","            return 1\n","        else:\n","            return 0\n","\n","def fun(arr):\n","        if arr in ['other_cyberbullying','gender','age','ethnicity','religion']:\n","            return 0\n","        else:\n","            return 1\n","def text_predict(custom_input):\n","    x=sentiment_analysis(custom_input)\n","    tokenizer=Tokenizer()\n","\n","    # Preprocess the custom input text in the same way as you did for the training data\n","    custom_input = re.sub(\"\\s+\", \" \", ' '.join([i for i in re.sub(\"[^9A-Za-z ]\", \"\" , re.sub(\"\\\\n\", \"\", re.sub(\"\\s+\", \" \", re.sub(r'http\\S+', '', custom_input.lower())))).split(\" \") if i not in stopwords]))\n","    custom_input = tokenizer.texts_to_sequences([custom_input])\n","    custom_input = pad_sequences(custom_input, maxlen=100, padding='post', truncating='post')\n","\n","    # Make the prediction using the model\n","    prediction = text_model.predict(custom_input)\n","\n","    # Get the index of the highest predicted class\n","    predicted_class_index = np.argmax(prediction)\n","\n","    # Get the corresponding label for the predicted class\n","    predicted_class = labels[predicted_class_index]\n","\n","    # print(\"The predicted cyberbullying type is:\", fun(predicted_class) or x )\n","    return fun(predicted_class)\n","\n","while(1):\n","  choice = input(\"Enter choice:\\n1.Text\\n2.Image\\n3.Audio\\n4.Exit\\n\")    \n","  if choice == '1':\n","      custom_input=str(input(\"Enter text to check whether it is bully or not\"))\n","      if text_predict(custom_input) == 0:\n","        print(\"The text is cyberbullying\")\n","      else:\n","        print(\"The text is not cyber bullying\")\n","      \n","  elif choice == '2':\n","      # Use files.upload() to upload an image file to Colab\n","      uploaded = files.upload()\n","      \n","      # Get the name of the uploaded file\n","      filename = next(iter(uploaded))\n","\n","      # Load the uploaded image as a PIL image object\n","      img_pil = Image.open(filename)\n","      # Resize the image to (224, 224) using PIL's resize() function\n","      img_pil_resized = img_pil.resize((224, 224))\n","\n","      # Convert the PIL image to a numpy array\n","      img_np = np.array(img_pil_resized)\n","\n","      # Use cv2.resize() to resize the numpy array to (224, 224)\n","      img = cv2.resize(img_np, (224, 224))\n","      # Convert the image to a numpy array\n","      img = np.array([img])\n","      # Use the model to make a prediction\n","      prediction = image_model.predict(img)\n","      predicted_label = \"Not Bullying\" if prediction[0][0] > 0.5 else \"Bullying\"\n","      print(predicted_label)\n","  elif choice == '3':\n","      # Load the MP3 file\n","      filename=input(\"Enter filename\")\n","      mp3_audio = AudioSegment.from_file(\"/content/drive/My Drive/Project/audios/\"+filename+\".mp3\", format=\"mp3\")\n","\n","    # Save the MP3 file as a WAV fil\n","      mp3_audio.export(\"audio.wav\", format=\"wav\")\n","\n","  # Transcribe the WAV file to text \n","      r = sr.Recognizer()\n","      audio_file = sr.AudioFile(\"audio.wav\")\n","\n","      with audio_file as source:\n","          audio_text = r.record(source)\n","\n","      result = r.recognize_google(audio_text, show_all=True)\n","      custom_input= result['alternative'][0]['transcript']\n","      print(custom_input)\n","      if text_predict(custom_input) == 1:\n","        print(\"The audio is cyberbullying\")\n","      else:\n","        print(\"The audio is not cyber bullying\")\n","  else:\n","    break"],"id":"9cd651d2-71ba-4462-a906-b76237bd192f"},{"cell_type":"code","execution_count":null,"metadata":{"id":"WavKgQS2SAH4"},"outputs":[],"source":[],"id":"WavKgQS2SAH4"}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"nbformat":4,"nbformat_minor":5}